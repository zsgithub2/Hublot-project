{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy \n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df_train = pd.read_csv('https://raw.githubusercontent.com/zsgithub2/Hublot-project/main/Data/training_data.csv')\n",
    "df_test = pd.read_csv('https://raw.githubusercontent.com/zsgithub2/Hublot-project/main/Data/test_data.csv')\n",
    "\n",
    "\n",
    "# create a new feature that also comprehend the keyword\n",
    "df_train['key_text'] = df_train['keyword'] + ' ' + df_train['text'] \n",
    "df_train['key_text'] = df_train['key_text'].astype(str)\n",
    "df_test['key_text'] = df_test['keyword'] + ' ' + df_test['text'] \n",
    "df_test['key_text'] = df_test['key_text'].astype(str)\n",
    "\n",
    "# Define tokenizer cleaner\n",
    "sp = spacy.load('en_core_web_sm') \n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS \n",
    "punctuations = string.punctuation\n",
    "\n",
    "\n",
    "# Tokenizer, I did it my self, i didn't used the pipeline we saw in class,\n",
    "# the reason is that I want the dataframe that comes as an output, if ever I want to modify it\n",
    "def tokenizer(message):\n",
    "    filtered_message = []  \n",
    "    for sentence in message:\n",
    "        processd_message = []\n",
    "        sentence = sp(sentence)\n",
    "        for word in sentence:\n",
    "            if str(word) not in punctuations:\n",
    "                if (word.is_stop == False) and (word.is_space == False):\n",
    "                    processd_message.append(word.lemma_.lower())\n",
    "        filtered_message.append(processd_message)\n",
    "\n",
    "    all_text = []\n",
    "    for text_list in filtered_message:\n",
    "        all_text.append(\"\"\" \"\"\".join(text_list))\n",
    "\n",
    "    count = CountVectorizer(ngram_range=(1,1), stop_words=\"english\")\n",
    "    bow = count.fit_transform(all_text)\n",
    "    feature_names = count.get_feature_names()\n",
    "    df_final = pd.DataFrame(bow.todense(), columns=feature_names)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 Test (Run this to get an Idea of how good is the program)\n",
    "X_train, X_test, y_train, y_test = train_test_split(tokenizer(df_train['key_text']), df_train['target'], test_size=0.2, random_state=72)\n",
    "\n",
    "classifier = LogisticRegressionCV(solver=\"lbfgs\",cv = 5, max_iter=1000, random_state=72)\n",
    "classifier.fit(X_train,y_train)\n",
    "pred = classifier.predict(X_test)\n",
    "print('You have to beat: ' + str(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "source": [
    "## previous results:\n",
    "\n",
    "The first submission we had an accuracy of (about) 0.794. Our final score was 0.81\n",
    "The first submission we had an accuracy of  0.80077. Our final score was 0.823\n",
    "\n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataframe\n",
    "tokens = tokenizer(pd.concat([df_train, df_test])['key_text'])\n",
    "\n",
    "# preparing the variables for the submission\n",
    "X_train = tokens[:len(df_train)]\n",
    "y_train = df_train['target']\n",
    "X_test = tokens[len(df_train):]\n",
    "\n",
    "# making the prediction\n",
    "classifier = LogisticRegressionCV(solver=\"lbfgs\", cv = 5, max_iter=1000, random_state=72)\n",
    "classifier.fit(X_train,y_train)\n",
    "pred = classifier.predict(X_test)\n",
    "\n",
    "# saving the prediction in csv (P.S. run this locally, I don't know if it works on colab)\n",
    "df = pd.DataFrame(pred, columns=['target'])\n",
    "df.to_csv('submission2.csv', index = False)"
   ]
  }
 ]
}